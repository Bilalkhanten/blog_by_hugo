word_counts <- tidy_cran %>%
anti_join(stop_words) %>%
group_by(word) %>%
filter(n() > 200) %>%
ungroup %>%
pairwise_count(word, Package, sort = TRUE, upper = FALSE)
word_counts
word_counts <- tidy_cran %>%
anti_join(stop_words) %>%
group_by(word) %>%
filter(n() > 200) %>%
ungroup %>%
pairwise_count(word, Package, sort = TRUE, upper = FALSE)
filtered_counts <- word_counts %>%
filter(n > 200,
item1 %in% word_totals$word,
item2 %in% word_totals$word)
vertices <- filtered_counts %>%
filter(word %in% filtered_cors$item1)
word_counts <- tidy_cran %>%
anti_join(stop_words) %>%
group_by(word) %>%
filter(n() > 200) %>%
ungroup %>%
pairwise_count(word, Package, sort = TRUE, upper = FALSE)
filtered_counts <- word_counts %>%
filter(n > 200,
item1 %in% word_totals$word,
item2 %in% word_totals$word)
vertices <- filtered_counts %>%
filter(word %in% filtered_counts$item1)
filtered_counts
vertices <- word_totals %>%
filter(word %in% filtered_counts$item1)
filtered_counts %>%
graph_from_data_frame(vertices = vertices) %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = n), width = 2) +
geom_node_point(aes(size = n), color = "cyan4")
word_counts <- tidy_cran %>%
anti_join(stop_words) %>%
group_by(word) %>%
filter(n() > 200) %>%
ungroup %>%
pairwise_count(word, Package, sort = TRUE, upper = FALSE)
filtered_counts <- word_counts %>%
filter(n > 200,
item1 %in% word_totals$word,
item2 %in% word_totals$word)
vertices <- word_totals %>%
filter(word %in% filtered_counts$item1)
filtered_counts
filtered_counts <- word_counts %>%
filter(n > 200,
item1 %in% word_totals$word,
item2 %in% word_totals$word) %>%
rename(count = n)
vertices <- word_totals %>%
filter(word %in% filtered_counts$item1)
filtered_counts
vertices
filtered_counts %>%
graph_from_data_frame(vertices = vertices) %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = count), width = 2) +
geom_node_point(aes(size = n), color = "cyan4")
word_counts
word_counts %>% View()
filtered_counts
vertices
word_counts <- tidy_cran %>%
anti_join(stop_words) %>%
group_by(word) %>%
filter(n() > 200) %>%
ungroup %>%
pairwise_count(word, Package, sort = TRUE)
filtered_counts <- word_counts %>%
filter(n > 200,
item1 %in% word_totals$word,
item2 %in% word_totals$word) %>%
rename(count = n)
vertices <- word_totals %>%
filter(word %in% filtered_counts$item1)
filtered_counts %>%
graph_from_data_frame(vertices = vertices) %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = count), width = 2) +
geom_node_point(aes(size = n), color = "cyan4")
filtered_counts %>%
graph_from_data_frame(vertices = vertices) %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = count), width = 2) +
geom_node_point(aes(size = n), color = "cyan4") +
geom_node_text(aes(label = name), repel = TRUE, point.padding = unit(0.3, "lines"),
family = "RobotoCondensed-Regular") +
theme_graph(base_family = "RobotoCondensed-Regular") +
scale_size_continuous(range = c(1, 15))
library(igraph)
library(ggraph)
library(widyr)
word_cors <- tidy_cran %>%
anti_join(stop_words) %>%
group_by(word) %>%
filter(n() > 200) %>%
ungroup %>%
pairwise_cor(word, Package, sort = TRUE)
filtered_cors <- word_cors %>%
filter(correlation > 0.2,
item1 %in% word_totals$word,
item2 %in% word_totals$word)
vertices <- word_totals %>%
filter(word %in% filtered_cors$item1)
set.seed(345)
filtered_cors %>%
graph_from_data_frame(vertices = vertices) %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), width = 2) +
geom_node_point(aes(size = n), color = "cyan4") +
geom_node_text(aes(label = name), repel = TRUE, point.padding = unit(0.3, "lines"),
family = "RobotoCondensed-Regular") +
theme_graph(base_family = "RobotoCondensed-Regular") +
scale_size_continuous(range = c(1, 15)) +
labs(size = "Number of packages",
edge_alpha = "Correlation",
title = "Word correlations in R package descriptions",
subtitle = "Which words are more likely to occur together than with other words?")
tidy_cran %>%
anti_join(stop_words) %>%
count(word, sort = TRUE)
tidy_cran %>%
anti_join(stop_words)
word_totals
word_totals %>%
top_n(20) %>%
ggplot(aes(word, n)) +
geom_col(fill = "midnightblue", alpha = 0.8) +
coord_flip() +
labs(x = NULL, y = "Number of uses in CRAN descriptions",
title = "What are the most commonly used words in CRAN package descriptions?",
subtitle = "After removing stop words")
word_totals %>%
top_n(20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col(fill = "midnightblue", alpha = 0.8) +
coord_flip() +
scale_x_discrete(expand = c(0,0)) +
labs(x = NULL, y = "Number of uses in CRAN descriptions",
title = "What are the most commonly used words in CRAN package descriptions?",
subtitle = "After removing stop words")
word_totals %>%
top_n(20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col(fill = "midnightblue", alpha = 0.8) +
coord_flip() +
scale_y_continuous(expand = c(0,0)) +
labs(x = NULL, y = "Number of uses in CRAN descriptions",
title = "What are the most commonly used words in CRAN package descriptions?",
subtitle = "After removing stop words")
library(igraph)
library(ggraph)
library(widyr)
word_cors <- tidy_cran %>%
anti_join(stop_words) %>%
group_by(word) %>%
filter(n() > 100) %>%
ungroup %>%
pairwise_cor(word, Package, sort = TRUE)
filtered_cors <- word_cors %>%
filter(correlation > 0.2,
item1 %in% word_totals$word,
item2 %in% word_totals$word)
vertices <- word_totals %>%
filter(word %in% filtered_cors$item1)
set.seed(345)
filtered_cors %>%
graph_from_data_frame(vertices = vertices) %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), width = 2) +
geom_node_point(aes(size = n), color = "cyan4") +
geom_node_text(aes(label = name), repel = TRUE, point.padding = unit(0.3, "lines"),
family = "RobotoCondensed-Regular") +
theme_graph(base_family = "RobotoCondensed-Regular") +
scale_size_continuous(range = c(1, 15)) +
labs(size = "Number of uses",
edge_alpha = "Correlation",
title = "Word correlations in R package descriptions",
subtitle = "Which words are more likely to occur together than with other words?")
library(igraph)
library(ggraph)
library(widyr)
word_cors <- tidy_cran %>%
anti_join(stop_words) %>%
group_by(word) %>%
filter(n() > 150) %>%
ungroup %>%
pairwise_cor(word, Package, sort = TRUE)
filtered_cors <- word_cors %>%
filter(correlation > 0.2,
item1 %in% word_totals$word,
item2 %in% word_totals$word)
vertices <- word_totals %>%
filter(word %in% filtered_cors$item1)
set.seed(345)
filtered_cors %>%
graph_from_data_frame(vertices = vertices) %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), width = 2) +
geom_node_point(aes(size = n), color = "cyan4") +
geom_node_text(aes(label = name), repel = TRUE, point.padding = unit(0.2, "lines"),
family = "RobotoCondensed-Regular") +
theme_graph(base_family = "RobotoCondensed-Regular") +
scale_size_continuous(range = c(1, 15)) +
labs(size = "Number of uses",
edge_alpha = "Correlation",
title = "Word correlations in R package descriptions",
subtitle = "Which words are more likely to occur together than with other words?")
library(igraph)
library(ggraph)
library(widyr)
word_cors <- tidy_cran %>%
anti_join(stop_words) %>%
group_by(word) %>%
filter(n() > 100) %>%
ungroup %>%
pairwise_cor(word, Package, sort = TRUE)
filtered_cors <- word_cors %>%
filter(correlation > 0.2,
item1 %in% word_totals$word,
item2 %in% word_totals$word)
vertices <- word_totals %>%
filter(word %in% filtered_cors$item1)
set.seed(345)
filtered_cors %>%
graph_from_data_frame(vertices = vertices) %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), width = 2) +
geom_node_point(aes(size = n), color = "cyan4") +
geom_node_text(aes(label = name), repel = TRUE, point.padding = unit(0.2, "lines"),
family = "RobotoCondensed-Regular") +
theme_graph(base_family = "RobotoCondensed-Regular") +
scale_size_continuous(range = c(1, 15)) +
labs(size = "Number of uses",
edge_alpha = "Correlation",
title = "Word correlations in R package descriptions",
subtitle = "Which words are more likely to occur together than with other words?")
filtered_cors %>%
graph_from_data_frame(vertices = vertices) %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = correlation), width = 2) +
geom_node_point(aes(size = n), color = "cyan4") +
geom_node_text(aes(label = name), repel = TRUE, point.padding = unit(0.2, "lines"),
family = "RobotoCondensed-Regular") +
theme_graph(base_family = "RobotoCondensed-Regular") +
theme(plot.title=element_text(family="Roboto-Bold")) +
scale_size_continuous(range = c(1, 15)) +
labs(size = "Number of uses",
edge_alpha = "Correlation",
title = "Word correlations in R package descriptions",
subtitle = "Which words are more likely to occur together than with other words?")
cran %>%
mutate(tests = ifelse(str_detect(Suggests, "testthat|RUnit"), TRUE, FALSE),
tests = ifelse(is.na(tests), FALSE, tests)) %>%
summarise(tests = mean(tests))
cran %>%
mutate(tests = ifelse(str_detect(Imports, "testthat|RUnit"), TRUE, FALSE),
tests = ifelse(is.na(tests), FALSE, tests)) %>%
summarise(tests = mean(tests))
cran %>%
mutate(tests = ifelse(str_detect(Depends, "testthat|RUnit"), TRUE, FALSE),
tests = ifelse(is.na(tests), FALSE, tests)) %>%
summarise(tests = mean(tests))
cran %>%
mutate(tests = ifelse(str_detect(Depends, "testthat|RUnit"), TRUE, FALSE),
tests = ifelse(is.na(tests), FALSE, tests)) %>%
count(tests)
cran %>%
mutate(tests = ifelse(str_detect(Imports, "testthat|RUnit"), TRUE, FALSE),
tests = ifelse(is.na(tests), FALSE, tests)) %>%
count(tests)
word_totals %>%
top_n(20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, color = word)) +
geom_col(alpha = 0.8) +
coord_flip() +
scale_y_continuous(expand = c(0,0)) +
labs(x = NULL, y = "Number of uses in CRAN descriptions",
title = "What are the most commonly used words in CRAN package descriptions?",
subtitle = "After removing stop words")
word_totals %>%
top_n(20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = word)) +
geom_col(alpha = 0.8) +
coord_flip() +
scale_y_continuous(expand = c(0,0)) +
labs(x = NULL, y = "Number of uses in CRAN descriptions",
title = "What are the most commonly used words in CRAN package descriptions?",
subtitle = "After removing stop words")
cran %>%
count(VignetteBuilder, sort = TRUE)
library(dplyr)
library(ggplot2)
# Observations belong to group 'a' or 'b'
group <- c("a","a","b","b","b","a", "a")
# Each observation can take on values of "low", "med", or "high"
values <- c("low","low","low","high","med","high", "high")
dat <- data_frame(group, values) %>%
count(group, values) %>%
group_by(group) %>%
mutate(percent = n / sum(n),
error = sqrt((percent * (1-percent))/n)) %>%
mutate(values = factor(values, levels = c("low", "med", "high")))
dat
ggplot(dat, aes(values, percent, fill = group)) +
geom_col(position = "dodge") +
geom_errorbar(aes(ymin = percent - error, ymax = percent + error),
position = position_dodge(0.9))
?tribble
df <- tribble(
~A, ~B, ~C, ~D,
1,  4,  5,  7,
2,  1,  4,  8,
12,  4,  6,  1,
4, 12,  1,  9
)
df %>% nest()
test <- df %>% nest()
test$data
test$data[[1]]
test <- df %>% nest(A:D)
test
test <- df %>% mutate(row = row_number() %>% nest(-row)
)
as;ljfalsj
test <- df %>% mutate(row = row_number()) %>% nest(-row)
test
df <- tribble(
~A, ~B, ~C, ~D,
1,  4,  5,  7,
2,  1,  4,  8,
12,  4,  6,  1,
4, 12,  1,  9
)
df %>%
mutate(row = row_number()) %>%
nest(-row)
setwd("~/Google Drive/data_science/blog/new_blog")
blogdown::install_theme("nurlansu/hugo-sustain")
blogdown::install_theme("jbub/ghostwriter")
blogdown::new_site()
blogdown::new_site()
blogdown::install_theme("nurlansu/hugo-sustain")
blogdown::serve_site()
blogdown::serve_site()
blogdown::install_theme("jpescador/hugo-future-imperfect")
blogdown::serve_site()
blogdown::install_theme("nodejh/hugo-theme-cactus-plus")
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::install_theme("kakawait/hugo-tranquilpeak-theme")
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::install_theme("digitalcraftsman/hugo-cactus-theme")
blogdown::serve_site()
blogdown::install_theme("vickylaiio/hugo-theme-introduction")
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
library(blogdown)
install_theme("nishanths/cocoa-hugo-theme")
serve_site()
serve_site()
getwd()
list.files(recursive = TRUE)
?list.files
list.files(pattern = "csv$", recursive = TRUE)
list.files(pattern = "md$", recursive = TRUE)
list.files(pattern = "csv$", recursive = TRUE)
?read.csv
library(tidyverse)
?read_csv
?map_df
?sample_n
serve_site()
vec1 <- c(3,6,7,NaN)
vec1[is.na(vec1)] <- 0
vec1
library(purrr)
vec1 <- c(3,6,7,NaN)
vec2 <- c(2,3,4)
vec3 <- c(1,6,NaN,NaN,1)
veclist <- list(a = vec1,
b = vec2,
c = vec3)
veclist
?map
map(veclist, function(x) x[is.na(x)] <- 0)
return_zero <- function(x){
x[is.na(x)] <- 0
x
}
map(veclist, return_zero)
library(reprex)
reprex(venue = "xo")
reprex(venue = "so")
install.packages("sos", repos="http://R-Forge.R-project.org")
library(sos)
findFn("sentiment")
?findFn
findFn("text mining")
findFn("{text mining}")
findFn("{text mining}")
serve_site()
serve_site()
?add_content
?new_content
new_content("content/blog/2017/05/17/testing.Rmd")
serve_site()
serve_site()
serve_site()
serve_site()
serve_site()
install_theme("shenoybr/hugo-goa")
install_theme("dldx/hpstr-hugo-theme")
serve_site()
library(blogdown)
install_theme("fuegowolf/cocoa-eh-hugo-theme")
serve_site()
serve_site()
serve_site()
serve_site()
serve_site()
install.packages("ggstance")
serve_site()
serve_site()
serve_site()
update.packages()
serve_site()
serve_site()
install.packages("ghostr")
install.packages("RSocrata")
water <- read.socrata("https://opendata.utah.gov/resource/j4aa-ce7s.csv")
library(RSocrata)
water <- read.socrata("https://opendata.utah.gov/resource/j4aa-ce7s.csv")
water
install.packages("streamgraph")
devtools::install_github("hrbrmstr/streamgraph")
# Chunk 1
library(knitr)
#library(svglite)
#knitr::opts_chunk$set(dev = "svglite", fig.ext = ".svg")
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE)
options(width=80)
# Chunk 2
library(RSocrata)
water <- read.socrata("https://opendata.utah.gov/resource/j4aa-ce7s.csv")
# Chunk 3
water <- water[grep("[0-9]{4}", water$YEAR),]
water <- water[!is.na(water$CONSUMPTION),]
water[,1:4] <- lapply(water[,1:4], as.factor)
water[,5:6] <- lapply(water[,5:6], as.numeric)
# Chunk 4
sapply(water, class)
dim(water)
# Chunk 5
library(dplyr)
monthtype <- water %>% group_by(MONTH, YEAR, TYPE) %>%
summarize(consumption = sum(CONSUMPTION))
# Chunk 6
library(ggplot2)
ggplot(monthtype, aes(x = TYPE, y = consumption, fill = TYPE)) +
geom_boxplot() +
theme(legend.position="none", axis.title.x = element_blank(),
axis.text.x= element_text(angle=45, hjust = 1)) +
ggtitle("Total Monthly Water Consumption in Salt Lake City") +
ylab("Total monthly water consumption (100 cubic ft)")
library(streamgraph)
library(dplyr)
water$date <- as.Date(paste0(water$YEAR,"-", water$MONTH, "-01"))
datetype <- water %>% group_by(date, TYPE) %>% summarize(consumption = sum(CONSUMPTION))
streamgraph(data = datetype, key = "TYPE", value = "consumption", date = "date",
offset = "zero", interpolate = "cardinal",
width = "750", height = "350") %>%
sg_fill_tableau("cyclic") %>%
sg_legend(TRUE, "Type: ") %>%
sg_axis_x(tick_interval = 1, tick_units = "year", tick_format = "%Y")
?read.socrata
water
water <- read.socrata("https://opendata.utah.gov/resource/j4aa-ce7s.csv")
water
water %>% count(YEAR)
library(streamgraph)
library(dplyr)
water$date <- as.Date(paste0(water$YEAR,"-", water$MONTH, "-01"))
datetype <- water %>% group_by(date, TYPE) %>% summarize(consumption = sum(CONSUMPTION))
streamgraph(data = datetype, key = "TYPE", value = "consumption", date = "date",
offset = "zero", interpolate = "cardinal",
width = "750", height = "350") %>%
sg_fill_tableau("cyclic") %>%
sg_legend(TRUE, "Type: ") %>%
sg_axis_x(tick_interval = 1, tick_units = "year", tick_format = "%Y")
water %>% count(MONTH)
rm(list = ls())
library(blogdown)
serve_site()
