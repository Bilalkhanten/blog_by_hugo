<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Julia Silge</title>
    <link>/</link>
    <description>Recent content on Julia Silge</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright © 2017 Julia Silge</copyright>
    <lastBuildDate>Thu, 04 May 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Mining CRAN DESCRIPTION Files</title>
      <link>/blog/mining-cran-description/</link>
      <pubDate>Thu, 04 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/mining-cran-description/</guid>
      <description>A couple of weeks ago, I saw on Dirk Eddelbuettel&amp;rsquo;s blog that R 3.4.0 was going to include a function for obtaining information about packages currently on CRAN, including basically everything in DESCRIPTION files. When R 3.4.0 was released, this was one of the things I was most immediately excited about exploring, because although I recently dabbled in scraping CRAN to try to get this kind of information, it was rather onerous.</description>
    </item>
    
    <item>
      <title>Gender Roles with Text Mining and N-grams</title>
      <link>/blog/gender-pronouns/</link>
      <pubDate>Sat, 15 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/gender-pronouns/</guid>
      <description>Today is the one year anniversary of the janeaustenr package&amp;rsquo;s appearance on CRAN, its cranniversary, if you will. I think it&amp;rsquo;s time for more Jane Austen here on my blog.
via GIPHY
I saw this paper by Matthew Jockers and Gabi Kirilloff a number of months ago and the ideas in it have been knocking around in my head ever since. The authors of that paper used text mining to examine a corpus of 19th century novels and explore how gendered pronouns (he/she/him/her) are associated with different verbs.</description>
    </item>
    
    <item>
      <title>How Do You Discover R Packages?</title>
      <link>/blog/package-search/</link>
      <pubDate>Mon, 20 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/package-search/</guid>
      <description>Like I mentioned in my last blog post, I am contributing to a session at userR 2017 this coming July that will focus on discovering and learning about R packages. This is an increasingly important issue for R users as we all decide which of the 10,000+ packages to invest time in understanding and then use in our work.
library(dplyr) available.packages() %&amp;gt;% tbl_df()  ## # A tibble: 10,276 × 17 ## Package Version Priority Depends ## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; ## 1 A3 1.</description>
    </item>
    
    <item>
      <title>Scraping CRAN with rvest</title>
      <link>/blog/scraping-cran/</link>
      <pubDate>Mon, 06 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/scraping-cran/</guid>
      <description>I am one of the organizers for a session at userR 2017 this coming July that will focus on discovering and learning about R packages. How do R users find packages that meet their needs? Can we make this process easier? As somebody who is relatively new to the R world compared to many, this is a topic that resonates with me and I am happy to be part of the discussion.</description>
    </item>
    
    <item>
      <title>What Programming Languages Are Used Most on Weekends?</title>
      <link>/blog/weekends-weekdays/</link>
      <pubDate>Tue, 07 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/weekends-weekdays/</guid>
      <description>Note: Cross-posted with the Stack Overflow blog. Check out the code for this analysis on Kaggle.
For me, the weekends are mostly about spending time with my family, reading for leisure, and working on the open-source projects I am involved in. These weekend projects overlap with the work that I do in my day job here at Stack Overflow, but are not exactly the same. Many developers tinker with side projects for learning or career development (or just for fun!</description>
    </item>
    
    <item>
      <title>Women in the 2016 Stack Overflow Survey</title>
      <link>/blog/women-survey/</link>
      <pubDate>Thu, 19 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/women-survey/</guid>
      <description>Note: Cross-posted with the Stack Overflow blog
The 2017 Stack Overflow Developer Survey opened last week, and we on the Data Team are looking forward to analyzing the survey results to better understand our developer community. I am particularly interested in women in tech, for probably obvious reasons, and recently I explored last year&amp;rsquo;s survey data to see what we can learn about women developers.
How many women took the developer survey?</description>
    </item>
    
    <item>
      <title>Text Mining in R: A Tidy Approach</title>
      <link>/blog/rstudio-conf/</link>
      <pubDate>Sat, 14 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/rstudio-conf/</guid>
      <description>I spoke on approaching text mining tasks using tidy data principles at rstudio::conf yesterday. I was so happy to have the opportunity to speak and the conference has been a great experience.
 
If you want to catch up on what has been going on at rstudio::conf, Karl Broman put together a GitHub repo of slides and Sharon Machlis has been live-blogging the conference at Computerworld. A highlight for me was Andrew Flowers&amp;rsquo; talk on data journalism and storytelling; I don&amp;rsquo;t work in data journalism but I think I can apply almost everything he said to how I approach what I do.</description>
    </item>
    
    <item>
      <title>Reddit Responds to the Election</title>
      <link>/blog/reddit-responds/</link>
      <pubDate>Tue, 06 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/reddit-responds/</guid>
      <description>It&amp;rsquo;s been about a month since the U.S. presidential election, with Donald Trump&amp;rsquo;s victory over Hillary Clinton coming as a surprise to most. Reddit user Jason Baumgartner collected and published every submission and comment posted to Reddit on the day of (and a bit surrounding) the U.S. election; let&amp;rsquo;s explore this data set and see what kinds of things we can learn.
Data wrangling This first bit was the hardest part of this analysis for me, probably because I am not the most experienced JSON person out there.</description>
    </item>
    
    <item>
      <title>Measuring Gobbledygook</title>
      <link>/blog/gobbledygook/</link>
      <pubDate>Fri, 25 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/gobbledygook/</guid>
      <description>In learning more about text mining over the past several months, one aspect of text that I&amp;rsquo;ve been interested in is readability. A text&amp;rsquo;s readability measures how hard or easy it is for a reader to read and understand what a text is saying; it depends on how sentences are written, what words are chosen, and so forth. I first became really aware of readability scores of books through my kids&amp;rsquo; reading tracking websites for school, but it turns out there are lots of frameworks for measuring readability.</description>
    </item>
    
    <item>
      <title>Mapping Election Results in Utah</title>
      <link>/blog/election-mapping/</link>
      <pubDate>Fri, 11 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/election-mapping/</guid>
      <description>My adopted home state of Utah has been a weird place this election cycle. For the unfamiliar, Utah is extremely conservative when it comes to politics; it is one of the reddest of the red states and has backed the Republican candidate for president for the past many decades. In 2012, about 3&amp;frasl;4 of the popular vote went to Mitt Romney (who is LDS, like many here in the state) and there were no counties where Mitt Romney did not win.</description>
    </item>
    
    <item>
      <title>Tidy Text Mining with R</title>
      <link>/blog/tidy-text-mining-with-r/</link>
      <pubDate>Fri, 28 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/tidy-text-mining-with-r/</guid>
      <description>I am so pleased to announce that tidytext 0.1.2 is now available on CRAN. This release of tidytext, a package for text mining using tidy data principles by Dave Robinson and me, includes some bug fixes and performance improvements, as well as some new functionality.
There is now a handy function for accessing the various lexicons in the sentiments dataset without the columns that are not used in that particular dataset; this makes these datasets even easier to use with pipes and joins from dplyr.</description>
    </item>
    
    <item>
      <title>Non-Academic Careers for Astronomers and Physicists</title>
      <link>/blog/non-academic-careers/</link>
      <pubDate>Fri, 30 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/non-academic-careers/</guid>
      <description>Today I&amp;rsquo;m giving a talk for the Department of Physics and Astronomy at the University of Utah about careers outside academia for astronomers and physicists. Check out my slides here, and links/references from my talk below.
 
 STEM PhD finishers in the UK (from the Royal Society) Science &amp;amp; Engineering PhDs awarded and faculty positions (from Nature) Declining proposal success rates in astronomy (from the National Science Foundation) Pamela Gay on soft money positions Katie Mack&amp;rsquo;s Twitter Josh Wills&amp;rsquo; Twitter Drew Conway Oliver Keyes on data science David Robinson on building public artifacts  </description>
    </item>
    
    <item>
      <title>Singing the Bayesian Beginner Blues</title>
      <link>/blog/bayesian-blues/</link>
      <pubDate>Wed, 28 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/bayesian-blues/</guid>
      <description>Earlier this week, I published a post about song lyrics and how different U.S. states are mentioned at different rates, and at different rates relative to their populations. That was a very fun post to work on, but you can tell from that paragraph near the end that I am a little bothered by the uncertainty involved in calculating the rates by just dividing two numbers. David Robinson suggested on Twitter that I might try using empirical Bayes methods to estimate the rates.</description>
    </item>
    
    <item>
      <title>Song Lyrics Across the United States</title>
      <link>/blog/song-lyrics-across/</link>
      <pubDate>Mon, 26 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/song-lyrics-across/</guid>
      <description>The inspiration for this post is a joint venture by both me and my husband, and its genesis lies more than 15 years in our past. One of the recurring conversations we have in our relationship (all long-term relationships have these, right?!) is about song lyrics and place names. I think the first time we ever had this conversation was in the late 1990s and was about Baltimore. &amp;ldquo;Why do so many songs talk about Baltimore?</description>
    </item>
    
    <item>
      <title>We Are Not Very Evenly Distributed</title>
      <link>/blog/evenly-distributed/</link>
      <pubDate>Fri, 19 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/evenly-distributed/</guid>
      <description>I saw this tweet making the rounds this past week.
Half of all Americans live in the red counties, half live in the orange counties pic.twitter.com/ptBXNbzSFQ
&amp;mdash; Conrad Hackett (@conradhackett) August 8, 2016 
Interesting! I saw people using this map to make the argument that the Electoral College was super important, or a terrible idea, or any of a number of other sociopolitical thoughts. This map certainly caught my attention and made me want to know more about this kind of population density distribution.</description>
    </item>
    
    <item>
      <title>Something Strange in the Neighborhood</title>
      <link>/blog/something-strange/</link>
      <pubDate>Fri, 05 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/something-strange/</guid>
      <description>Today I was so pleased to see a new data package hit CRAN, and how wonderful to see such accomplished women writing R packages.
What a great new data package on CRAN! And always great to see more women authors in #rstats https://t.co/nROMibqPxX pic.twitter.com/UEayWgx9bz — Julia Silge (@juliasilge) August 5, 2016   The ghostr package includes a dataset of over 800 ghost sightings in Kentucky, with information on city, latitude, and longitude, along with URLs for finding more information about the ghost sightings.</description>
    </item>
    
    <item>
      <title>Return of the NEISS Data</title>
      <link>/blog/return-of-neiss/</link>
      <pubDate>Fri, 22 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/return-of-neiss/</guid>
      <description>Almost six months ago (!) I wrote a blog post about the NEISS data set, a sample of accidents reported to emergency rooms in the U.S. that are related to consumer products. Ever since I did that exploration, I have been wanting to ask a bit of a different question from that sample of accidents. How do the accidents that people suffer depend on their demographic characteristics? We can get a bit of a sense of that from looking at the plot with age on the x-axis (or exploring Hadley Wickham&amp;rsquo;s NEISS Shiny app) but the NEISS data set includes quite a bit more demographic information to interact with.</description>
    </item>
    
    <item>
      <title>Fatal Police Shootings Across the U.S.</title>
      <link>/blog/fatal-shootings/</link>
      <pubDate>Thu, 07 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/fatal-shootings/</guid>
      <description>I have been full of grief and sadness and some anger in the wake of yet more videos going viral in the past couple days showing black men being killed by police officers. I am not an expert on what it means to be a person of color in the United States or what is or isn&amp;rsquo;t wrong with policing today here, but it sure feels like something is deeply broken.</description>
    </item>
    
    <item>
      <title>Term Frequency and tf-idf Using Tidy Data Principles</title>
      <link>/blog/term-frequency-tf-idf/</link>
      <pubDate>Mon, 27 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/term-frequency-tf-idf/</guid>
      <description>At the end of last week, Dave Robinson and I released a new version of tidytext on CRAN, our R package for text mining using tidy data principles. You can check out my first blog post about tidytext to learn a bit about the philosophy of the package and see some of the ways to use it, or see the package on GitHub. In this new release (tidytext 0.1.1), we have added more documentation, fixed some bugs, developed better testing/CI, and added some new functionality.</description>
    </item>
    
    <item>
      <title>A Beginner&#39;s Guide to Travis-CI for R</title>
      <link>/blog/beginners-guide-to-travis/</link>
      <pubDate>Fri, 20 May 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/beginners-guide-to-travis/</guid>
      <description>Have you seen all those attractive green badges on other people&amp;rsquo;s R packages and thought, &amp;ldquo;I want a lovely green badge!&amp;rdquo;
Always a nice feeling when Travis manages to actually build. #runconf16 pic.twitter.com/7qZfH2OEij
&amp;mdash; Julia Silge (@juliasilge) April 1, 2016 
OF COURSE YOU DO. Well, let&amp;rsquo;s give it a shot, because today I am going to attempt a beginner&amp;rsquo;s guide to using Travis-CI for continuous integration for R packages.</description>
    </item>
    
    <item>
      <title>The Life-Changing Magic of Tidying Text</title>
      <link>/blog/life-changing-magic/</link>
      <pubDate>Fri, 29 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/life-changing-magic/</guid>
      <description>When I went to the rOpenSci unconference about a month ago, I started work with Dave Robinson on a package for text mining using tidy data principles. What is this tidy data you keep hearing so much about? As described by Hadley Wickham, tidy data has a specific structure:
 each variable is a column each observation is a row each type of observational unit is a table  This means we end up with a data set that is in a long, skinny format instead of a wide format.</description>
    </item>
    
    <item>
      <title>How I Learned to Stop Worrying and Love R CMD Check</title>
      <link>/blog/how-i-stopped/</link>
      <pubDate>Mon, 18 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/how-i-stopped/</guid>
      <description>Last week, I officially became the maintainer of a CRAN package! My package for the texts of Jane Austen&amp;rsquo;s 6 completed, published novels, janeaustenr, was released on CRAN and my Twitter feed was filled with congratulatory Jane Austen GIFs. I think this might be my favorite.
.@juliasilge clears schedule
*opens @rstudio * pic.twitter.com/Hu7V2E0ULJ
&amp;mdash; Andrew MacDonald (@polesasunder) April 15, 2016 
It was a good day.
During the process of getting janeaustenr ready to submit to CRAN, I was pointed to some resources that were very helpful to me as a first-time maintainer.</description>
    </item>
    
    <item>
      <title>Who Came to Vote in Utah&#39;s Caucuses?</title>
      <link>/blog/who-came-to-vote/</link>
      <pubDate>Fri, 08 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/who-came-to-vote/</guid>
      <description>Late last month, I analyzed results from Utah&amp;rsquo;s Republican and Democratic caucuses to show how the different presidential candidates fared across Utah. That was fun work to do, but I realized there was one more map I wanted to make; I want to compare the Republican and Democratic voter turnout across the counties in Utah. Utah is a politically conservative state and we know from the last plot I made in that post that many more people voted in the Republican caucus than the Democratic caucus, but I would like to see how voter turnout was distributed across the state.</description>
    </item>
    
    <item>
      <title>I Went to ROpenSci Unconference and All I Got Were These Lousy Hex Stickers</title>
      <link>/blog/i-went-to-ropensci/</link>
      <pubDate>Wed, 06 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/i-went-to-ropensci/</guid>
      <description>Just kidding; it was amazing.
Last week, I traveled to San Francisco to participate in an unconference/hackathon organized and hosted by ROpenSci. This was my first R conference or meeting, and it was a such a great experience. I am still feeling a bit at a loss for words about what a tremendous time I had, actually, but I will make an attempt to share a bit about what it was like and what we did.</description>
    </item>
    
    <item>
      <title>Trump Losing and Feeling the Bern in Utah</title>
      <link>/blog/mapping-utah-caucus/</link>
      <pubDate>Fri, 25 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/mapping-utah-caucus/</guid>
      <description>Well, it&amp;rsquo;s been an interesting election season so far, right? Everybody holding up OK? Utah held its caucuses this past Tuesday on March 22 and I thought I would do a bit of plotting to show the results. We can get the JSON data from CNN, as pointed out by Bob Rudis in his post here. Utah&amp;rsquo;s results were not available when he wrote that post but I was able to poke around and find them using the guidance he provided there.</description>
    </item>
    
    <item>
      <title>If I Loved Natural Language Processing Less, I Might Be Able to Talk About It More</title>
      <link>/blog/if-i-loved-natural-language-processing-less-i-might-be-able-to-talk-about-it-more/</link>
      <pubDate>Fri, 18 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/if-i-loved-natural-language-processing-less-i-might-be-able-to-talk-about-it-more/</guid>
      <description>In my last post, I did some natural language processing and sentiment analysis for Jane Austen&amp;rsquo;s most well-known novel, Pride and Prejudice. It was just so much fun that I wanted to extend some of that work and compare across her body of writing.
I decided to make an R package for her texts, for easy access for myself and anybody else who would like to do some text analysis on a nice sample of prose.</description>
    </item>
    
    <item>
      <title>You Must Allow Me To Tell You How Ardently I Admire and Love Natural Language Processing</title>
      <link>/blog/you-must-allow-me/</link>
      <pubDate>Tue, 08 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/you-must-allow-me/</guid>
      <description>It is a truth universally acknowledged that sentiment analysis is super fun, and Pride and Prejudice is probably my very favorite book in all of literature, so let&amp;rsquo;s do some Jane Austen natural language processing.
Project Gutenberg makes e-texts available for many, many books, including Pride and Prejudice which is available here. I am using the plain text UTF-8 file available at that link for this analysis. Let&amp;rsquo;s read the file and get it ready for analysis.</description>
    </item>
    
    <item>
      <title>My Baby Boomer Name Might Have Been &#34;Debbie&#34;</title>
      <link>/blog/my-baby-boomer-name/</link>
      <pubDate>Mon, 29 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/my-baby-boomer-name/</guid>
      <description>I have always loved learning and thinking about names, how they are chosen and used, and how people feel about their names and the names around them. We had a traditional baby name book at our house when I was growing up (you know, lists of names with meanings), and I remember poring over it to find unusual or appealing names for my pretend play or the stories I wrote.</description>
    </item>
    
    <item>
      <title>Your Floor Is the Most Dangerous Thing In Your House</title>
      <link>/blog/your-floor/</link>
      <pubDate>Wed, 17 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/your-floor/</guid>
      <description>I saw this analysis at Flowing Data about the most common consumer products involved in hospital ER visits and was delighted, interested, etc. Nathan&amp;rsquo;s next related post is, um, also super interesting, if entirely horrifying. Apparently, I am not the only one who thought this data set was compelling, because this week Hadley Wickham took the NEISS data set that these beautiful analyses are based on and made an R package for them.</description>
    </item>
    
    <item>
      <title>A Tall Drink of Water</title>
      <link>/blog/tall-drink-of-water/</link>
      <pubDate>Thu, 11 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/tall-drink-of-water/</guid>
      <description>In a previous post, I used water consumption data from Utah&amp;rsquo;s Open Data Catalog to explore what kind of users consume the most water in my home here in Salt Lake City, what the annual pattern of water use is, and how the drought of the past few years has affected water use. I made a predictive model for the total aggregate water use of the city and tested how drought affected the accuracy of such a model.</description>
    </item>
    
    <item>
      <title>Death Comes to Us All</title>
      <link>/blog/death-comes/</link>
      <pubDate>Fri, 05 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/death-comes/</guid>
      <description>I have been working with a data set on causes of death in my adopted home state of Utah for a little while now, and I had been struggling with the best way to visualize it. This week, David Robinson released the gganimate package to create animated ggplot2 plots and I thought &amp;ldquo;AH HA! This is what I have needing.&amp;rdquo; The data on causes of death in Utah is available here via Utah&amp;rsquo;s Open Data Catalog and can be accessed via Socrata Open Data API.</description>
    </item>
    
    <item>
      <title>Connecting Religion and Demographics</title>
      <link>/blog/connecting-religion/</link>
      <pubDate>Mon, 01 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/connecting-religion/</guid>
      <description>I have my second guest post up today at Ari Lamstein&amp;rsquo;s blog where I conclude my exploration of the Religious Congregations and Membership Study at the ARDA. In this post I show how we can look at the relationships between a data set like the religion census and demographic data to gain context and understanding. Go over there to read the details!</description>
    </item>
    
    <item>
      <title>More Fun with Choropleth Maps</title>
      <link>/blog/more-fun-with-maps/</link>
      <pubDate>Mon, 25 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/more-fun-with-maps/</guid>
      <description>I have a guest post up today at Ari Lamstein&amp;rsquo;s blog where I show some more fun things that can be done with the Religious Congregations and Membership Study at the ARDA that I used to look at Utah. I looked in some detail at Iowa ahead of their caucus in a few days, in light of all the news lately about Republican presidential candidates courting evangelical voters. Go take a look to read more!</description>
    </item>
    
    <item>
      <title>Water World</title>
      <link>/blog/water-world/</link>
      <pubDate>Tue, 19 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/water-world/</guid>
      <description>I live in Utah, an extremely dry state. Like much of the western United States, Utah is experiencing water stress from increasing demand, episodes of drought, and conflict over water rights. At the same time, Utahns use a lot of water per capita compared to residents of other states. According to the United States Geological Survey, in 2014 people in Utah used more water per person than in any other state, and in years before and after, Utah’s per capita water use is always near the very top in the U.</description>
    </item>
    
    <item>
      <title>Health Care Indicators in Utah Counties</title>
      <link>/blog/health-care-indicators/</link>
      <pubDate>Mon, 11 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/health-care-indicators/</guid>
      <description>The state of Utah (my adopted home) has an Open Data Catalog with lots of interesting data sets, including a collection of health care indicators from 2014 for the 29 counties in Utah. The observations for each county include measurements such as the infant mortality rate, the percent of people who don&amp;rsquo;t have insurance, what percent of people have diabetes, and so forth. Let&amp;rsquo;s see how these health care indicators are related to each other and if we can use these data to cluster Utah counties into similar groups.</description>
    </item>
    
    <item>
      <title>This Is the Place, Apparently</title>
      <link>/blog/this-is-the-place/</link>
      <pubDate>Sun, 03 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/this-is-the-place/</guid>
      <description>My family and I moved to Utah about 5 years ago and we have found ourselves thoroughly in love in with our new home state. I didn&amp;rsquo;t know much about it before we began the process of contemplating a move here, and I find that is often true of many people. Let&amp;rsquo;s use some choropleth maps and demographic exploration to learn a bit more about this place I call home now.</description>
    </item>
    
    <item>
      <title>Joy to the World, and also Anticipation, Disgust, Surprise...</title>
      <link>/blog/joy-to-the-world/</link>
      <pubDate>Tue, 22 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>/blog/joy-to-the-world/</guid>
      <description>In my previous blog post, I analyzed my Twitter archive and explored some aspects of my tweeting behavior. When do I tweet, how much do retweet people, do I use hashtags? These are examples of one kind of question, but what about the actual verbal content of my tweets, the text itself? What kinds of questions can we ask and answer about the text in some programmatic way? This is what is called natural language processing, and I&amp;rsquo;ll give a first shot at it here.</description>
    </item>
    
    <item>
      <title>Ten Thousand Tweets</title>
      <link>/blog/ten-thousand-tweets/</link>
      <pubDate>Tue, 08 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>/blog/ten-thousand-tweets/</guid>
      <description>I started learning the statistical programming language R this past summer, and discovering Hadley Wickham&amp;rsquo;s data visualization package ggplot2 has been a joy and a revelation. When I think back to how I made all the plots for my astronomy dissertation in the early 2000s (COUGH SUPERMONGO COUGH), I feel a bit in awe of what ggplot2 can do and how easy and, might I even say, delightful it is to use.</description>
    </item>
    
    <item>
      <title>about</title>
      <link>/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>My name is Julia Silge and I am a data scientist at Stack Overflow. I love making beautiful charts, the statistical programming language R, Jane Austen, black coffee, and red wine.
I studied physics and astronomy, finishing my PhD in 2005. I worked in academia (teaching and doing research) and ed tech before moving into data science and discovering R. Now, my background in astronomy, physics, and education has given me a strong foundation for using data to answer interesting questions and communicate about technical topics with diverse audiences.</description>
    </item>
    
    <item>
      <title>resume</title>
      <link>/resume/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/resume/</guid>
      <description>Professional Profile I am a PhD data scientist who loves to answer interesting questions with sophisticated analytical tools and techniques. I am a creative problem solver who knows how to ask insightful questions and how to learn quickly. I understand how to think critically, and I have proven writing and speaking abilities. Analyzing and interpreting complex datasets makes me happy, and I am known for being flexible, resourceful, and for achieving goals while maintaining a positive outlook.</description>
    </item>
    
  </channel>
</rss>